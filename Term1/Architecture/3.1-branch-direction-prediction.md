branch prediction is important: control hazard is really an issue in pipeline designs; branches occurs frequently(1 in 5?) especially in multi-issue designs; relative effect of stalls is larger in a multi-issue design whose CPI is lower according to Amdahl's Law; its idea can also be used in other kinds of dynamic prediction in arch design

dynamic scheduling can handle conditional jumps/virtual call(by indirect jumps)/page faults, but misprediction is expensive

alternatives: if a core has enough threads(multithreading), we can use predication/delayed branch?

what is multithreading: assume we have *enough* threads(not only 1 or 2) each of which has its unique PC and registers, cycle0 fetch from t0, cycle1 fetch from t1 in a Round-Robin style; so we have enough time to determine the branch target; cons: single thread perf is bad

predication: add 1-bit predicate registers storing flags; whether some instructions will execute depends on the value of predicate registers; turn control hazards into data hazards; partial support from some ISAs; more efficient if multi-issue; good if hard to predict, eliminate the risks

delayed branch: delay slot in MIPS; single delay slot is sufficient to allow data forwarding; use what to fill the delay slot: instructions near the jump, or targeted instruction; compiler effectiveness: 60% of slot are filled(I think, a non-nop instruction) and 80% of them are useful, so overall 50% usefully filled; 'cancelling' branches: slot instructions are executed but not able to write back **if it's not supposed to be executed**, branches can be marked as 'likely taken' or 'likely not taken', increase the utilization of the slots???; downside: all things will change if pipeline becomes deeper or multi-issue(superscalar) is enabled



BP context: fetch correct instruction without any stalls; even before the next instruction is decoded.

two different BP: direction prediction(jump or not); target prediction(jump, but address yet to be predicted, for example, virtual call or return addresses)



simplest: branch history table(BHT), indexed by k low-order bits, update taken/not taken after execution, predict as what is recorded in the table; cons: aliasing problem(like associativity conflict in cache), embedded loop(inner loop always suffers from the first and the last iteration, but they can be avoided)

dynamic branch prediction(2-bit BHT): 2-bit state, 0~3, taken -=1 or stay, not taken +=1 or stay, 0-1 predict taken, 2-3 predict not taken, this can mitigate the embedded loop problem, 2-bit always very good while some cases it's not good, some cases it'd be better if we increase k(bigger table),

problem of n-bit BHT: it's highly biased, some instructions are not always taken nor not taken; local history, associated with a specific branch

now non-local! For example:

```c
if (C1) then {...}
if (C2) then {...}
if (C3) then {...}
```

Sometimes `c1/c2/c3` are corelated, for example, if we know that `c1` is true, then `c2/c3` should also be true. So *global history!*

shift register for all previously executed branches, m-bit branch history register(BHR), so $2^m$ n-bit BHTs with total $n2^{m+k}$ if every BHT is indexed by lower k bits. This is called an (n,m) gselect predicator.

variations:

* (n,m) combinations
* global only, ignore local PC information, i.e. k=0
* gshare: BHT indexed by XOR result
* PAP

extreme program example: go, not a bimodal, experiment showed that as total size of all the BHTs increased, it's more accurate but more global bits were needed

think twice about the appropriateness of the benchmark: In some benchmark, 5 branches cover 90% of the jumps of overall 500 branches, but in real programs, things are not the same

tournament predicator: 2 predicators, also a predicator to decide which predicator to use, update both predicator when committing

profiling(???) is good, but tournament is better 

overall, tournament can benefit from total predicator size more effectively


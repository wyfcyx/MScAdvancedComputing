## flash disks(including SSD)

random read as fast as sequential read, but random write is still slow, writing cycles are limited especially under improper use, unit: blocks, access time of blocks from different location are nearly the same compared with the disk,

structure: flash - flash package - dies - planes - blocks - pages

complicated software driver(or firmware): flash translation layer, FTL, balance of the data distribution to extend the lifetime of the ssd?

access time depends on: device organization/software driver efficiency/bandwidth of flash packages

random write is expensive since it requires a page copy and deletion(pages are isolated, so if they aren't at the same level, it would be time-consuming to turn around), seq write we can keep the data in mem and operate them all together

flash disks vs. HDD: efficient random read, more expensive(in terms GB/$)

usage of flash disks: fill the gap of the latency(4-5 orders difference now) and bandwidth between RAM and HDD(2-3 order difference now)

trends of flash disks: density(upward but facing limitations such as trade-off among density, capacity and errors), bulk erase size(problematic, getting slower), latency(good, improving but slow), endurance(bad)

trends of phase-change memory: density(too low but improving), latency(very good, so it's potential for it to find a place in the mem's hierarchy), endurance(?)

## DBMS and SSD

many ideas of classical DBMS are based on disks, buffer manager -> latency difference between mem and disk, transaction -> parallel; wait data from the disk, buffer pool/B+ tree

SSD, not an ideal HDD replacement, depends on the workload/dataset/access pattern

## how to use SSD

### 1. Flash-only OLTP(online transaction processing)

many random but minor reads/writes, which flash may fit it

diagram of the flash perf: significantly drop as time goes(we call it variability, even unpredictable after 20hrs cuz it fluctuates), so we cannot just replace the disks with it

new algorithm: when we're writing, append only, if we want to update, just append the new data and invalidate the previous one, run out of space -> reclaim, *turn random writes into sequential writes*

Q1: if the pages we want to write are isolated physically on the flash, how can we sequentially write them?

result: high throughput, still variability but more predictable

### 2. flash-aided business intelligence, OLAP(online analytical processing)

more read-only queries, but scattered updates as well, how to combine them

query only: 1 time unit of execution, update in place: 2, batch update: 1.2 but no data freshness, ideal case: just as query only

use SSD as a write cache, do not cache the updates in the memory, good random read, not so good random write(random->seq), not so good endurance(FTL)

Q2: what's the difference between keep M mirror pages and cache the updates in the memory?

coarse or fine grained index: how to find the updates on flash/mirrored pages

### 3. logging on flash+HDD

transactional logging: not so good on HDD cuz they're small seq writes

on SSD it's good!



 